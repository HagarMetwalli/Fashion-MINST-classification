{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch has two main packages :\n",
    "# torch and torchvision \n",
    "\n",
    "# torch is the main package \n",
    "#torchvision package that contain model , datasets and transforms methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.datasets import FashionMNIST \n",
    "from torchvision.models import vgg16\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formla to claclulate output of conv layer\n",
    "\n",
    "    input is : n,w,h\n",
    "    output :n_new , w_new , h_new\n",
    "    n_new = out_channels\n",
    "    w_new = (w - kernal + 2 padding)/stride + 1 \n",
    "    h_new = (h - kernal + 2 padding)/stride + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3b8a943026e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFashionMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\elfakhrany\\Documents\\computer_vision\\data\\FashionMNIST'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[0;32m     72\u001b[0m                                ' You can use download=True to download it')\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "batch = 20\n",
    "train_data = FashionMNIST(r'C:\\Users\\elfakhrany\\Documents\\session2\\data',train=True,transform=transforms.ToTensor(),download=False)\n",
    "trainloader = DataLoader(train_data,batch_size=batch,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get some Info About data\n",
    "iterator = iter(trainloader)\n",
    "images , labels = iterator.next()\n",
    "print(\"Num of images in  training data is {}\".format(len(train_data)))\n",
    "print('Images shape is : {}'.format(images.shape))\n",
    "print('Lables shape is : {}'.format(labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check labels \n",
    "print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so what is Data classes ? \n",
    "# we can find it from Data repo : https://github.com/zalandoresearch/fashion-mnist\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot some images \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = images.numpy()\n",
    "print(images.shape)\n",
    "images = np.transpose(images,(0,2,3,1)) #pytorch images has shape (channels , w , h) but plt need (w,h,channels)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(2,10,i+1)\n",
    "    ax.imshow(np.squeeze(images[i]),cmap='gray')\n",
    "    ax.set_title(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # Here we build our Network arch\n",
    "        # we know that input shpe is (1,28,28)\n",
    "        self.conv1 = nn.Conv2d(1,16,3,padding=1) #shpae = (16,28,28)\n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1) #shpae = (32,28,28)\n",
    "        self.pool1 = nn.MaxPool2d(2,2) # shape (32, 14, 14)\n",
    "        self.conv3 = nn.Conv2d(32,64,3) #shpae = (64 ,12,12)\n",
    "        self.fc = nn.Linear(12*12*64,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # x is data passed to out network so we mush feed it forword to all layers \n",
    "        # self.conv() return linear output so we use F.relu -Activation function- to non-linearity \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.softmax(self.fc(x),dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model before training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just want to know how our model will do with data without ant training \n",
    "so we know **Load** test data and feed it to out <bold >net</bold> and claculate it's accurecy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = FashionMNIST('./data/',train=False,transform=transforms.ToTensor())\n",
    "testloader = DataLoader(test_data,batch_size=batch,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one batch of test data to feed it to model\n",
    "images , lables = iter(testloader).next()\n",
    "images , labels = images , labels\n",
    "outs = net(images)\n",
    "pre = torch.argmax(outs ,dim=1)\n",
    "true = (pre == labels).sum().numpy()\n",
    "print(\"Accurecy for one batch is :{}\".format(true/batch))\n",
    "print(\"predected classes is : {}\".format(pre))\n",
    "print(\"true classes is : {}\".format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start train we should define our loss function and out optimizer and num of epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1 # we should start with small num to test our model and change any thing then we set final epoch \n",
    "num_of_batches = len(train_data)//batch\n",
    "#print(num_of_batches)\n",
    "print(\"Training start...\")\n",
    "net.train()\n",
    "for i in range(epoch):\n",
    "    epoch_err = 0.0\n",
    "    batches_err = 0.0\n",
    "    for batch_i , data in enumerate(trainloader):\n",
    "        images , labels = data\n",
    "        images , labels = images , labels\n",
    "        opt.zero_grad()\n",
    "        outs = net(images)\n",
    "        err = cost(outs,labels)\n",
    "        err.backward()\n",
    "        opt.step()\n",
    "        batches_err+=err.item()\n",
    "        epoch_err+=batches_err\n",
    "        if(batch_i%1000 == 999): #print avg batch loss every 1000 batches\n",
    "            print(\"Epoch {} , Batch {} , Avg loss {}\".format(i+1,batch_i+1,batches_err/1000))\n",
    "\n",
    "            \n",
    "            batches_err=0.0\n",
    "    \n",
    "    print(\"--------\\n Epoch {} Error is : {}\\n--------\".format(i+1,epoch_err/(num_of_batches)))\n",
    "print(\"Training Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize tensor and lists to monitor test loss and accuracy\n",
    "test_loss = torch.zeros(1)\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "\n",
    "# set the module to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "for batch_i, data in enumerate(testloader):\n",
    "    \n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, labels = data\n",
    "    inputs = inputs\n",
    "    labels = labels\n",
    "    # forward pass to get outputs\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = cost(outputs, labels)\n",
    "            \n",
    "    # update average test loss \n",
    "    test_loss = test_loss + ((torch.ones(1) / (batch_i + 1)) * (loss.data - test_loss))\n",
    "    \n",
    "    # get the predicted class from the maximum value in the output-list of class scores\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(predicted.eq(labels.data.view_as(predicted)))\n",
    "    \n",
    "    # calculate test accuracy for *each* object class\n",
    "    # we get the scalar value of correct items for a class, by calling `correct[i].item()`\n",
    "    for i in range(batch):\n",
    "        label = labels.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss.numpy()[0]))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "        \n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = 'saved_models/'\n",
    "model_name = 'model_1.pt'\n",
    "\n",
    "torch.save(net.state_dict(), model_dir+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate your Net\n",
    "# this refers to your Net class defined above\n",
    "net = Net()\n",
    "\n",
    "# load the net parameters by name\n",
    "# uncomment and write the name of a saved model\n",
    "net.load_state_dict(torch.load('saved_models/model_1.pt'))\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predected classes is : {}\".format(predicted))\n",
    "print(\"true classes is : {}\".format(correct))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
